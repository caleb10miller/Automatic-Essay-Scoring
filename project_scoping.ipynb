{"cells":[{"cell_type":"markdown","metadata":{"id":"zkQDuZm9pIiJ"},"source":["## Project submission header\n","### Submission preparation instructions \n","_Completion of this header is mandatory, subject to point deduction to the scoping assignment._ Only add plain text in the designated areas, i.e., replacing the relevant 'NA's. You must fill out all group member Names and Drexel email addresses in the below markdown list, under header __Project group__. It is required to fill out descriptive notes pertaining to any __External support and stakeholders__, including project mentors (i.e., your advisors) or collaborative relationships in the completion of this submission under the __Additional submission comments__ section at the bottom of the header; please list any supplementary comments pertaining to the submissions in the section labeled __Other__. If no other support was received or parties are involved, leave NA for these sections. \n","\n","For these projects, the target group sizes should be 3&ndash;4 students, but large groups of 5&ndash;6 will be allowed with justification:\n","> if you wish to conduct your project in a large group of more than 4, you must complete the __Large groups justification__ section, which should express why exactly your project will particularly benefit from the larger group, e.g., if you're all working together on a capstone project that you'd like to enrich with NLP+DL. Additionally, large groups are required to submit an additional statement on __Group workload management__, desc\n","\n","_Any distruption of this header's formatting will make your group liable to a possible point deduction._\n","\n","### Project group\n","- Group member 1\n","    - Name:  Luke Chesley\n","    - Email: lc3368@drexel.edu\n","- Group member 2\n","    - Name: Lauren Miller\n","    - Email: lem324@drexel.edu\n","- Group member 3\n","    - Name: Caleb Miller \n","    - Email: cm3962@drexel.edu\n","- Group member 4\n","    - Name: Hashim Afzal\n","    - Email: ha695@drexel.edu\n","\n","### Additional submission comments\n","- External support and stakeholders: NA\n","- Other (other): NA\n","- Large groups justification: NA"]},{"cell_type":"markdown","metadata":{"id":"E4roU5IlbvJb"},"source":["# DSCI 691: Natural Language Processing with Deep Learning <br> Term Project Phase 1: Scoping"]},{"cell_type":"markdown","metadata":{"id":"KnB9M_yJbvJe"},"source":["## Overview\n","As this is an elective course, you all presumably know some idea of why you're here, i.e., you have some concept of what NLP and DL are and interest in working with building systems which rely on state-of-the-art language learning techniques.\n","\n","So this is&mdash;like for many other DSCI courses&mdash;the first portion of a two-part, open-ended team assignment. Term projects will account for 40% of your overall grade, and this scoping section is worth 10% (1/4 of the project). The other 3/4 will include project performance and culminate in a presentation during the last week of class or the regularly scheduled final exam period. As an upper-level elective course, this one is designed to support research and research-oriented and open-ended curricular requirements, like capstones, funded research work, theses, and dissertations.\n","\n","All projects for this course will entail the following two phases:\n","\n","1. (this) scoping phase, which must include the following main components:\n","    - the review of a research paper relevant to your project and write-up of a summary and\n","    - a NLP+DL project description; which will be followed by\n","2. (the next) performance phase, covering exporation and prototyping of an application's function or of an empirical investigation, i.e., applying NLP+DL to illustrate a scientific reserach question.\n","\n","__Important__: Please fill out this Jupyter notebook to complete your project scoping and submit the completed copy with any supplementary materials attached. Specific requirements are listed below. _Each member of each must submit their own exact-same copy of the scoping document._"]},{"cell_type":"markdown","metadata":{"id":"KQqR8G2gbvJg"},"source":["## 1. Project and team formation (1 pt)\n","\n","The first thing you'll have to do in this phase is organize into a project team. \n","\n","Be sure to consider the range of strengths in your group and their interests in NLP+DL, as it will help to discuss these in defining a project. Be sure to write out the names of the project team's members in this first report, below, and answer the two questions:\n","\n","1. What areas/skills/domains does the team member presently identify with?\n","\n","Luke Chesley currently identifies with skills and experience relating to the implementation of deep learning models in PyTorch. He has experience building language models for sequence classification and hopes to expand this knowledge to other tasks throughout this project. \n","\n","Lauren Miller is currently demonstrating a strong commitment to learning and problem-solving. Since beginning her MS degree in fall 2024, she has made significant strides in her learning journey and remains dedicated to expanding her knowledge through the data science curriculum.\n","\n","Caleb Miller currently shows strong skills within data analytics and visualization from prior knowledge (BS Business Analytics). Through his MSDS program, he has improved his skills in object oriented programming, applied machine learning, evaluating model performance, and network analysis. \n","\n","Hashim Afzal possesses a diverse skill set that spans multiple domains. With a background in academic research, Hashim has a wealth of experience in designing experiments, analyzing data, and drawing conclusions. With experience working with large datasets, conducting literature reviews, and synthesizing information from various sources, Hashim brings an analytical mindset and problem solving skills.\n","\n","2. Into which areas/skills/domains would the team member like to grow?\n","\n","Luke Chesley would like to grow in his understanding of the equations that govern the deep learning process, to rely less on \"black box\" understanding of topics and build a strong foundation for how these systems work. \n","\n","Lauren Miller would like to grow in her overall knowledge of natural language processing. Specifically in building neural networks and understanding the complexity and reasons behind the model. \n","\n","Caleb Miller wold like to grow his skills in machine learning (specifically by moving from Scikit-Learn on to Keras/Pytorch/TensorFlow) and improve his understanding in natural language processing (to understand what math is going on in the background of neural networks, etc.). \n","\n","Hashim Afzal would like to grow his conceptual understanding on how deep learning networks operate. Specifically how different algorithms and systems are developed.\n"]},{"cell_type":"markdown","metadata":{"id":"t2oC-6q0bvJh"},"source":["### Project title, abstract, and expanded team description\n","\n","Here, you should provide and informative name (this can be updated later) for your project, in addition to a 150-word maximum project abstract, providing a short, intuitive description of the project's intent.\n","- Title: Automatic Essay Grading Using Machine Learning: Enhancing Assessment Efficiency and Accuracy\n","- Abstract: \n","    The traditional approach to grading essays is labor intensive, time consuming, and subjective. In response to these challenges, this project uses machine learning (ML) techniques for automatic essay grading. By using natural language processing (NLP) and ML algorithms, our system aims to potentially aid in streamlining the grading process while maintaining a high level of accuracy and fairness. The ultimate goal of this project is to develop a robust and scalable system. By automating the grading process, educators can save time and ensure consistency and objectivity in assessments. \n","\n","Additionally, each team member must fill out the below information. \n","\n","- Group member 1\n","    - Name: Luke Chesley\n","    - Interests: The \n","    - Background: Luke earned his Bachelor’s degree from University of the Arts in Instrumental Performance - Bass Trombone. He continues his career as a professional musician, performing with the groups such as the Reading Symphony Orchestra and The Philly Pops among others, while attending Drexel University to earn a Master’s degree in Data Science. \n","- Group member 2\n","    - Name: Lauren Miller\n","    - Interests: Exploring the intersection of natural language processing and deep learning. Applying advanced machine learning techniques to solve complex language-related problems. Her interests outside of the classroom include reading, knitting and yoga. \n","    - Background: Lauren holds a Bachelor's degree in Food Science from Drexel University and has a strong foundation in biotechnology. Following her undergraduate studies, she accumulated two years of industry experience, working at a food science company and a biomass fermentation startup. Motivated by a passion for data-driven insights, Lauren embarked on a journey to expand her expertise by pursuing a Master's degree in Data Science at Drexel University. She is enjoys situations that involves analytical thinking and problem-solving. \n","- Group member 3\n","    - Name: Caleb Miller\n","    - Interests: Despite having only briefly worked in NLP through projects with NLTK and SpaCy, Caleb has a fascination with the field and is eager to learn more. Specifically, he is interested in learning what is going on behind the scenes of sentiment analysis, text summarization, and conversational chatbots. Caleb understands how ML algorithms train based off numerical data (becaue they can understand this), however, he is intersted in learning how we can teach a system to understand text data (i.e. the difference between angry and sad, etc). \n","    - Background: Caleb’s undergraduate background in Business Analytics gives him a unique perspective on Data Science. He has general knowledge of how a business operates, technical knowledge of an analyst/data scientist, and understands the divide between these departments and the executive suite. He aims to be a bridge between these departments. He has worked with a lot of data relating to sports, as his hope is to enter the world of sports analytics/science. His self identified skills include: Python, R, Java, C++, SQL, VBA, Pandas, NumPy, Dash, Matplotlib, Tableau, PowerBI, Model Development and Evaluation, Scikit-Learn, Requests, Selenium, BeautifulSoup4, Monte Carlo Simulation\n","- Group member 4\n","    - Name: Hashim Afzal\n","    - Interests: While Hashim has not formally undergone education regarding NLP + DL, he is intrigued by delving into sentiment analysis within the realm of Natural Language Processing (NLP) by unraveling the complexities of sentiments embedded within textual data. He is captivated by the art of discerning emotions, opinions, and attitudes.\n","    - Background: Hashim has an undergraduate degree in Biology from Arizona State University and has completed research in the field of cellular biology at the Biodesign Institute studying infectious diseases. Upon leaving Arizona State University, Hashim worked as an analyst where he wrote and implemented transaction monitoring rules. Now Hashim is at Drexel University studying Data Science. His self-identified skills are in statistical analysis and study design utilizing the scientific method.\n","    \n","### Group workload management \n","Note: this section is only required for large groups of 5 or more, and is otherwise optional."]},{"cell_type":"markdown","metadata":{"id":"yHaMtpuGbvJi"},"source":["## 2. Research paper summary (4 pts)\n","This first section of your proposal must summarize a relevant research to approximately 2 pages/1000 words in the markdown cell, below. Here, you're required to write a summary written at a level that your classmates will understand. Hence, and new terminology or technical details not covered in the scheduled course topics will need to be covered in detail, but you should avoid spending space on course-covered content. First, list the metadata for the research paper\n","\n","Note: please be critical of the literature you select and reach out to your instructor and/or TAs to ensure it is of high quality. If you select a paper that has not passed through peer review, please understand it may not be fully resolved or evaluated research."]},{"cell_type":"markdown","metadata":{"id":"3MIehqNebvJk"},"source":["### Paper summary metadata\n","Please place your paper's metadata in the labeled sections below.\n","- Title: Automated essay scoring: A review of the field\n","- Link: https://ieeexplore.ieee.org/document/9618476\n","- Bibliographical information: P. Lagakis and S. Demetriadis, \"Automated essay scoring: A review of the field,\" 2021 International Conference on Computer, Information and Telecommunication Systems (CITS), Istanbul, Turkey, 2021, pp. 1-6, doi: 10.1109/CITS52676.2021.9618476."]},{"cell_type":"markdown","metadata":{"id":"T36xMqOYbvJk"},"source":["### Description of paper-review sections\n","In your 2-page summary, you must complete the following sections:\n","1. __Justification__: a justification for the review, which _must cover why_ this paper is relevant to your project;\n","2. __Background__: a background of the paper, e.g., related work, research motivation, and placement in the history of NLP research; \n","3. __Impact__: a summary of contributions, e.g., what the paper teaches us and how it has or may impact the NLP community; and finally\n","4. __Discussion__: a discussion of the work and its limitations, e.g., where the work loses applicability or needs improvement or expansion and possible directions for future work. "]},{"cell_type":"markdown","metadata":{"id":"splm3NxFbvJl"},"source":["_Please fill out the below sections to complete your __Research paper summary__._\n","### Summary"]},{"cell_type":"markdown","metadata":{"id":"u_m7FkyebvJl"},"source":["#### 2.1 Justification\n","Please justify how this paper connects and informs your term project.\n","\n","This paper reviews the recently published scientific literature on the task of Automated Essay Scoring (AES). For this term project, we are using The Hewlett Foundation: Automated Essay Scoring dataset to create an AES system. \n","\n","This paper informs our term project in many ways. To begin with, the paper reviews the literature of AES systems and discusses a number of their distinguishing characteristics. The paper expands upon these characteristics that have been identified and analyzed such as the model of the system and the features used. It also discusses the most common datasets used to train the models, the scoring methods (holistic or dimensional), and the evaluation metrics. The overall goal of the paper is to provide an overview of the AES systems literature while referencing other papers that will aid in our term project as well. All of these factors need to be taken into consideration when building an AES model such as the one we are planning to build for this term project. \n"]},{"cell_type":"markdown","metadata":{"id":"b7hWzCR8bvJm"},"source":["#### 2.2. Background\n","Please discuss how this paper fits into the broader NLP research literature in this section and particularly relates to other reserch.\n","\n","This paper outlines milestones of Automated Essay Scoring (AES) from the creation of the field in 1966 as well as current trends, practices, and developments in modern AES systems. AES is the process of automating the evaluation of answers to open-ended questions by utilizing NLP techniques.  AES is most used in educational settings. \n","\n","AES system research aligns with broader NLP literature on machine learning and evaluation metrics. Techniques and models developed in AES research can be applied to other text classification tasks, and vice versa.  AES research often explores different features and representations of text, including linguistic features, syntactic structures, and semantic embeddings. This aligns with broader NLP research on feature engineering and representation learning, where researchers investigate methods for capturing and representing the semantics of natural language.\n","\n","Researchers in AES explore techniques for domain adaptation and transfer learning to improve model generalization. This research intersects with broader NLP literature, where similar challenges are addressed in various NLP tasks.\n"]},{"cell_type":"markdown","metadata":{"id":"vn9PSB45bvJp"},"source":["#### 2.3 Impact\n","Please discuss how the results of this paper impact other NLP reserach and the broader community which utilizes NLP in domain-specific applications.\n","\n","This paper offers insights into the methodologies used in AES systems. This includes the machine learning algorithms, natural language processing techniques, and linguistic features. These approaches can be combined and used in different ways to positively impact the effectiveness and accuracy of the AES systems discussed. This paper discusses the distinguishing characteristics of AES research. This allows the authors to holistically identify areas in which research could continue to facilitate improvement in this domain. \n","\n","Overall, insights from AES research can be applied to the broader community which utilizes NLP in domain-specific applications, particularly those involving text classification, sentiment analysis, and content evaluation. Algorithms developed for AES, such as feature extraction and scoring algorithms could be adapted, expanded, and/or extended to address similar tasks in other domains. \n"]},{"cell_type":"markdown","metadata":{"id":"gX_PKrUvbvJp"},"source":["#### 2.4 Discussion\n","Please discuss what the results of the paper's research ultimately produced, where, e.g., it's applicability stopped and how it can be improved and/or expanded upon in future work, _especially including your work here in this project_.\n","\n","The discussion included in this paper is vast and important to our topic. The paper uses four characteristics to distinguish the existing AES systems. These characteristics are methods, scoring, datasets, and metrics. AES systems are also categorized in regards to the features they use- the two systems used are handcrafted features and systems with neural approaches that extract features automatically. \n","\n","Handcrafted features:\n","Early AES systems were developed with handcrafted features. Handcrafted features can be modified to better enable evaluating specific aspects of an essay, and potentially provide feedback to the author of the essay. Some common handcrafted features include length-based features, syntactic features, word-based features, readability, semantics, argumentation, and prompt-relevance. \n","\n","Automated feature extraction:\n","Automated feature extraction in AES systems erases the need for feature engineering by following neural approaches. The paper discusses  a model that automatically creates the features needed through a model that has an input of one-hot vector words that are fed to a convolution layer that extracts n-gram level features. These features are passed through a recurrent layer of a Long-Short Term Memory network (LSTM) that extracts a second vector of features. Another paper uses a similar approach, but uses score-specific word embeddings (SSWEs) instead of training the embeddings to find similarities in unannotated corpora (a collection of text). Other automated feature extraction models propose the use of the structure of an essay to be in two stages, the word-level and the sentence-level. Each stage acts as input on their own convolution layer. \n","\n","Overall, both feature extraction methods have advantages and disadvantages. Neural approaches with automatic feature engineering are valuable at extracting semantic features that are difficult to model by hand. But, in order to be effective Neural approaches with automatic feature engineering require large datasets which are difficult to acquire (especially for languages other than English). Hand-crafted features can be better used in dimension-specific AES systems. \n","\n","Transformer based models: \n","The paper continues to discuss transformer-based models, which is a current trend in the NLP community. Transformer architecture was introduced in 2017 and established by Bidirectional Encoder Representations from Transformers (BERT). The transformer model enables better parallelization during training and the option of training on larger datasets. The paper further details methodology while citing papers of different components and methods that could be included in a transformer model. Some of these methodologies including combining regression and ranking models in the AES systems, and the Two-Stage Learning Framework (TSLF). \n","\n","Overall, improvement can be made in the size and quality of the  datasets available for AES systems. Exploration into the scoring of different aspects of an essay is a topic that could aid in addition research. AES systems have an opportunity to provide great value for educational applications and more. \n"]},{"cell_type":"markdown","metadata":{"id":"7c-X1FwIbvJq"},"source":["## 3. Full project description (5 pts)\n","The full project description has six sections, covering the following (below). \n","\n","### Description of project description sections\n","\n","1. __Project goals__: the main goals of the project, including any high level information like scientific questions you're trying to answer, deployment scenarios your trying satisfy, or how this project's NLP pipeline fits into a larger application context.\n","2. __NLP task description__: the NLP task you'll address, which should discuss the specific NLP task that your project will cover as it relates to others in the NLP research literature, or, if your task is non-standard, should develop a precise task description and place it _near_ others in the research literature.\n","3. __Project data__: a desription which should address how the your project's task is exactly formulated in data, e.g., discussing the task information connects to some typed output and over what units, like tokens or spans or if/how it's related to generation.\n","4. __Neural methodology__: a description of the neural method(s) that you intend to employ/explore towards the satisfaction of your project's goals and why this approach is appropriate for the specific task.\n","5. __Baselines__: the baselines you'll use for comparison with your neural methodology, and which should illustrate what's 'easily' accomplished in your task by standard, conventional, rule- or frequency-based, naïve, and otherwise simplified but illustrative approaches to task satisfaction.\n","6. __Evaluation__: an plan for how you will evaluatate the performance of your model against the baselines, including any expected experiental design criteria and approaches to exploration of hyperparameters, including, e.g., ablation studies and cross-validations etc."]},{"cell_type":"markdown","metadata":{"id":"v0TRZbiYbvJq"},"source":["_To complete your __Project description__, please fill out the below markdown sections._\n","### Description"]},{"cell_type":"markdown","metadata":{"id":"f6OzQqZDbvJr"},"source":["#### 3.1 Project goals\n","Please place project goals description here.\n","\n","The goal of this project is to create an Automatic Essay Scoring (AES) system. We plan to do this using The Hewlett Foundation: Automated Essay Scoring dataset. This dataset is from the Automated Student Assessment Prize (ASAP) competition on essay scoring that was first released as part of a Kaggle competition in 2012 and sponsored by the Hewlett Foundation. This dataset is referenced in the paper as one of the top five most broadly used English datasets that are known for training AES mechanisms. "]},{"cell_type":"markdown","metadata":{"id":"D1tB-qAZbvJs"},"source":["#### 3.2 NLP task description\n","Please describe your NLP project's task here. If your task is not a 'traditional' NLP task, please describe how it relates to others or is itself novel.\n","\n","Our task is to build a NLP AES model that will allow high school essays contained in the dataset to be scored accurately. "]},{"cell_type":"markdown","metadata":{"id":"EaKok7k5bvJs"},"source":["#### 3.3 Project data\n","Please describe _all_ data you expect to use in this project, including both task data and any supplementary or external resources.\n","\n","In this dataset there are eight essay sets. Each of the sets of essays was generated from a single prompt. Essays range from an average length of 150 to 550 words per response. All responses were written by students ranging in grade levels from Grade 7 to Grade 10. All essays were hand graded and were double-scored. The essays are in response to a prompt which covers various topics and essay types, such as argumentative essays, narrative essays, or explanatory essays.\n","\n","Link to project data: https://www.kaggle.com/c/asap-aes\n"]},{"cell_type":"markdown","metadata":{},"source":["The training data has the following columns: \n","\n","essay_id: A unique identifier for each individual student essay\n","\n","essay_set: 1-8, an id for each set of essays\n","\n","essay: The ascii text of a student's response\n","\n","rater1_domain1: Rater 1's domain 1 score; all essays have this\n","\n","rater2_domain1: Rater 2's domain 1 score; all essays have this\n","\n","rater3_domain1: Rater 3's domain 1 score; only some essays in set 8 have this.\n","\n","domain1_score: Resolved score between the raters; all essays have this\n","\n","rater1_domain2: Rater 1's domain 2 score; only essays in set 2 have this\n","\n","rater2_domain2: Rater 2's domain 2 score; only essays in set 2 have this\n","\n","domain2_score: Resolved score between the raters; only essays in set 2 have this\n","\n","rater1_trait1 score - rater3_trait6 score: trait scores for sets 7-8\n"]},{"cell_type":"markdown","metadata":{},"source":["The validation and test files each have 6 columns:\n","\n","essay_id: A unique identifier for each individual student essay\n","\n","essay_set: 1-8, an id for each set of essays\n","\n","essay: The ascii text of a student's response\n","\n","domain1_predictionid: A unique prediction_id that corresponds to the predicted_score on the essay for domain 1; all essays have this\n","\n","domain2_predictionid: A unique prediction_id that corresponds to the predicted_score on the essay for domain 2; only essays in set 2 have this"]},{"cell_type":"markdown","metadata":{},"source":["Drawback of the data include the score limits are not universal for all prompts. This makes it difficult to train a model on various prompts. Another drawback is that the essays have crucial alterations from the original scripts. An example of this is as follows: paragraphs are not distinguished from one another and capitalized letters are being erased."]},{"cell_type":"markdown","metadata":{"id":"WYF2g2NqbvJt"},"source":["#### 3.4 Neural methodology\n","Please describe the neural processing methods you intend to employ for your task.\n","\n","We plan to train pre-defined models (scaled down Llama 2) from scratch on our classification task.\n","\n","The model was adapted from this torchtitan implementation: [link](https://github.com/pytorch/torchtitan/blob/main/torchtitan/models/llama/model.py)\n","\n","This implementation was initially designed for text generation so the architecture was adjusted slightly to fit the classification task. The output of the last layer of the base model, instead of being fed to a linear layer that maps tensors to vocabulary dimension, is fed to an average pooling layer, then to a linear layer which has a final output dimension of 5 to match the number of possible scores in our dataset.\n","\n","The model uses rotary embeddings to encode positional information, and multi-head masked self-attention. \n","\n","Initially we plan to use randomly initialized token embeddings that will be learned, but may explore leveraging pre-trained embeddings. \n","\n","For a tokenizer we implemented a Byte-pair encoding tokenizer using the tokenizers library from huggingface.  \n","\n"]},{"cell_type":"markdown","metadata":{"id":"vCe8qefebvJt"},"source":["#### 3.5 Baselines\n","Please describe the baselines you intend to set up as a comparison for your neural models.\n","\n","Our initial baseline will be a Naive Bayes classification model. It is naive based on Bayes' Theorem with an independence assumption among predictors. \n","\n","Our second baseline will be a machine learning model that will be fed handcrafted features such as 'num_chars_essay', 'num_puncts_essay', 'num_words_essay', 'num_unique_words_essay', 'num_noun', and 'num_adj'. \n"]},{"cell_type":"markdown","metadata":{"id":"3SSGzA3RbvJw"},"source":["#### 3.6 Evaluation\n","Please describe your performance metrics that you'll utilize for evaluation and how they provide critical insight to how we should expect a deployed application to function.  \n","\n","The evaluation metrics that are widely used in AES systems are quadratic weighted kappa error metric agreement metric rating between -1 and 1. \n","Other metrics for evaluation include Mean Absolute Error (MAE) and Mean Square Error (MSE) and correlation metrics such as Pearson’s Correlation Coefficient (PCC) and Spearman’s Correlation Coefficient (SCC). \n","\n","The quadratic weight kappa error metric typically varies from -1 (only random agreement between raters) to 1 (complete agreement between raters).  In the event that there is less agreement between the raters than expected by chance, this metric may go below 0. "]}],"metadata":{"colab":{"collapsed_sections":[],"name":"project-1.ipynb","provenance":[],"toc_visible":true},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.5"}},"nbformat":4,"nbformat_minor":0}
